{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('./final.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\" or pg_sleep  (  __TIME__  )  --</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>create user name identified by pass123 tempora...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AND 1  =  utl_inaddr.get_host_address   (    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>select * from users where id  =  '1' or @ @1 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>select * from users where id  =  1 or 1#\"  ( ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Sentence  Label\n",
       "0           0                  \" or pg_sleep  (  __TIME__  )  --      1\n",
       "1           1  create user name identified by pass123 tempora...      1\n",
       "2           2   AND 1  =  utl_inaddr.get_host_address   (    ...      1\n",
       "3           3   select * from users where id  =  '1' or @ @1 ...      1\n",
       "4           4   select * from users where id  =  1 or 1#\"  ( ...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25674 entries, 0 to 25673\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  25674 non-null  object\n",
      " 1   Label     25674 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 401.3+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# vectorization of data\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer( min_df=2, max_df=0.7, max_features=4096, stop_words=stopwords.words('english'))\n",
    "posts = vectorizer.fit_transform(df['Sentence'].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25674, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.shape=(25674,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = posts/np.max(posts)\n",
    "X=posts\n",
    "np.max(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(64,64,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2359552   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,770,433\n",
      "Trainable params: 2,770,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "161/161 [==============================] - 95s 578ms/step - loss: 0.3193 - accuracy: 0.8590 - val_loss: 0.1993 - val_accuracy: 0.9281\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 87s 541ms/step - loss: 0.1725 - accuracy: 0.9393 - val_loss: 0.1534 - val_accuracy: 0.9451\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 86s 536ms/step - loss: 0.1424 - accuracy: 0.9488 - val_loss: 0.1419 - val_accuracy: 0.9482\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 86s 537ms/step - loss: 0.1248 - accuracy: 0.9573 - val_loss: 0.1299 - val_accuracy: 0.9548\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 88s 548ms/step - loss: 0.1163 - accuracy: 0.9603 - val_loss: 0.1288 - val_accuracy: 0.9554\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 87s 538ms/step - loss: 0.1139 - accuracy: 0.9611 - val_loss: 0.1192 - val_accuracy: 0.9599\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 87s 540ms/step - loss: 0.1091 - accuracy: 0.9623 - val_loss: 0.1173 - val_accuracy: 0.9581\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 88s 546ms/step - loss: 0.1060 - accuracy: 0.9633 - val_loss: 0.1202 - val_accuracy: 0.9574\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 87s 540ms/step - loss: 0.1086 - accuracy: 0.9622 - val_loss: 0.1211 - val_accuracy: 0.9599\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 87s 538ms/step - loss: 0.1057 - accuracy: 0.9636 - val_loss: 0.1173 - val_accuracy: 0.9607\n"
     ]
    }
   ],
   "source": [
    "classifier_nn = model.fit(X_train,y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "model.save('cnn.h5')\n",
    "with open('vectorizer_cnn', 'wb') as fin:\n",
    "    pickle.dump(vectorizer, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "mymodel = load_model('cnn.h5')\n",
    "myvectorizer = pickle.load(open(\"vectorizer_cnn\", 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_data(input_val):\n",
    "\n",
    "    input_val=input_val.replace('\\n', '')\n",
    "    input_val=input_val.replace('%20', ' ')\n",
    "    input_val=input_val.replace('=', ' = ')\n",
    "    input_val=input_val.replace('((', ' (( ')\n",
    "    input_val=input_val.replace('))', ' )) ')\n",
    "    input_val=input_val.replace('(', ' ( ')\n",
    "    input_val=input_val.replace(')', ' ) ')\n",
    "    input_val=input_val.replace('1 ', 'numeric')\n",
    "    input_val=input_val.replace(' 1', 'numeric')\n",
    "    input_val=input_val.replace(\"'1 \", \"'numeric \")\n",
    "    input_val=input_val.replace(\" 1'\", \" numeric'\")\n",
    "    input_val=input_val.replace('1,', 'numeric,')\n",
    "    input_val=input_val.replace(\" 2 \", \" numeric \")\n",
    "    input_val=input_val.replace(' 3 ', ' numeric ')\n",
    "    input_val=input_val.replace(' 3--', ' numeric--')\n",
    "    input_val=input_val.replace(\" 4 \", ' numeric ')\n",
    "    input_val=input_val.replace(\" 5 \", ' numeric ')\n",
    "    input_val=input_val.replace(' 6 ', ' numeric ')\n",
    "    input_val=input_val.replace(\" 7 \", ' numeric ')\n",
    "    input_val=input_val.replace(\" 8 \", ' numeric ')\n",
    "    input_val=input_val.replace('1234', ' numeric ')\n",
    "    input_val=input_val.replace(\"22\", ' numeric ')\n",
    "    input_val=input_val.replace(\" 8 \", ' numeric ')\n",
    "    input_val=input_val.replace(\" 200 \", ' numeric ')\n",
    "    input_val=input_val.replace(\"23 \", ' numeric ')\n",
    "    input_val=input_val.replace('\"1', '\"numeric')\n",
    "    input_val=input_val.replace('1\"', '\"numeric')\n",
    "    input_val=input_val.replace(\"7659\", 'numeric')\n",
    "    input_val=input_val.replace(\" 37 \", ' numeric ')\n",
    "    input_val=input_val.replace(\" 45 \", ' numeric ')\n",
    "\n",
    "    return input_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_sqli_attack():\n",
    "    \n",
    "    repeat=True\n",
    "    \n",
    "    beautify=''\n",
    "    for i in range(20):\n",
    "        beautify+= \"=\"\n",
    "\n",
    "    print(beautify) \n",
    "    input_val=input(\"Give me some data to work on : \")\n",
    "    print(beautify)\n",
    "\n",
    "    \n",
    "    if input_val== '0':\n",
    "        repeat=False\n",
    "    \n",
    "    \n",
    "\n",
    "    input_val=clean_data(input_val)\n",
    "    input_val=[input_val]\n",
    "\n",
    "\n",
    "\n",
    "    input_val=myvectorizer.transform(input_val).toarray()\n",
    "\n",
    "    result=mymodel.predict(input_val)\n",
    "\n",
    "\n",
    "    print(beautify)\n",
    "    \n",
    "    \n",
    "    if repeat == True:\n",
    "        \n",
    "        if result>0.5:\n",
    "            print(\"ALERT :::: This can be SQL injection\")\n",
    "\n",
    "\n",
    "        elif result<=0.5:\n",
    "            print(\"It seems to be safe\")\n",
    "            \n",
    "        print(beautify)\n",
    "            \n",
    "        predict_sqli_attack()\n",
    "            \n",
    "    elif repeat == False:\n",
    "        print( \" Good Bye \")\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "====================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 64, 64, 1), found shape=(None, 4096)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict_sqli_attack()\n",
      "Cell \u001b[1;32mIn [3], line 78\u001b[0m, in \u001b[0;36mpredict_sqli_attack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m input_val\u001b[39m=\u001b[39m[input_val]\n\u001b[0;32m     76\u001b[0m input_val\u001b[39m=\u001b[39mmyvectorizer\u001b[39m.\u001b[39mtransform(input_val)\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m---> 78\u001b[0m result\u001b[39m=\u001b[39mmymodel\u001b[39m.\u001b[39;49mpredict(input_val)\n\u001b[0;32m     81\u001b[0m \u001b[39mprint\u001b[39m(beautify)\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m repeat \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filettbmvyvh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ASUS\\miniconda3\\envs\\datasci\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 64, 64, 1), found shape=(None, 4096)\n"
     ]
    }
   ],
   "source": [
    "predict_sqli_attack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
